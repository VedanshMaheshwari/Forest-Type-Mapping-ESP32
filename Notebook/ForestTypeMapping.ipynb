{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53d6cced-f321-4935-8260-b3df31f1fa26",
   "metadata": {},
   "source": [
    "# Forest Type Mapping Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29700239-8da9-4bfa-8973-28456b72a4f1",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c68bb90-d097-4bc3-8f52-f541dcafedab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e6e5303-8244-48aa-bddf-3ba71849f040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>b8</th>\n",
       "      <th>b9</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_minus_obs_H_b9</th>\n",
       "      <th>pred_minus_obs_S_b1</th>\n",
       "      <th>pred_minus_obs_S_b2</th>\n",
       "      <th>pred_minus_obs_S_b3</th>\n",
       "      <th>pred_minus_obs_S_b4</th>\n",
       "      <th>pred_minus_obs_S_b5</th>\n",
       "      <th>pred_minus_obs_S_b6</th>\n",
       "      <th>pred_minus_obs_S_b7</th>\n",
       "      <th>pred_minus_obs_S_b8</th>\n",
       "      <th>pred_minus_obs_S_b9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d</td>\n",
       "      <td>39</td>\n",
       "      <td>36</td>\n",
       "      <td>57</td>\n",
       "      <td>91</td>\n",
       "      <td>59</td>\n",
       "      <td>101</td>\n",
       "      <td>93</td>\n",
       "      <td>27</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.36</td>\n",
       "      <td>-18.41</td>\n",
       "      <td>-1.88</td>\n",
       "      <td>-6.43</td>\n",
       "      <td>-21.03</td>\n",
       "      <td>-1.60</td>\n",
       "      <td>-6.18</td>\n",
       "      <td>-22.50</td>\n",
       "      <td>-5.20</td>\n",
       "      <td>-7.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>h</td>\n",
       "      <td>84</td>\n",
       "      <td>30</td>\n",
       "      <td>57</td>\n",
       "      <td>112</td>\n",
       "      <td>51</td>\n",
       "      <td>98</td>\n",
       "      <td>92</td>\n",
       "      <td>26</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.26</td>\n",
       "      <td>-16.27</td>\n",
       "      <td>-1.95</td>\n",
       "      <td>-6.25</td>\n",
       "      <td>-18.79</td>\n",
       "      <td>-1.99</td>\n",
       "      <td>-6.18</td>\n",
       "      <td>-23.41</td>\n",
       "      <td>-8.87</td>\n",
       "      <td>-10.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s</td>\n",
       "      <td>53</td>\n",
       "      <td>25</td>\n",
       "      <td>49</td>\n",
       "      <td>99</td>\n",
       "      <td>51</td>\n",
       "      <td>93</td>\n",
       "      <td>84</td>\n",
       "      <td>26</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.46</td>\n",
       "      <td>-15.92</td>\n",
       "      <td>-1.79</td>\n",
       "      <td>-4.64</td>\n",
       "      <td>-17.73</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>-4.69</td>\n",
       "      <td>-19.97</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>-7.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s</td>\n",
       "      <td>59</td>\n",
       "      <td>26</td>\n",
       "      <td>49</td>\n",
       "      <td>103</td>\n",
       "      <td>47</td>\n",
       "      <td>92</td>\n",
       "      <td>82</td>\n",
       "      <td>25</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>2.68</td>\n",
       "      <td>-13.77</td>\n",
       "      <td>-2.53</td>\n",
       "      <td>-6.34</td>\n",
       "      <td>-22.03</td>\n",
       "      <td>-2.34</td>\n",
       "      <td>-6.60</td>\n",
       "      <td>-27.10</td>\n",
       "      <td>-7.99</td>\n",
       "      <td>-10.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d</td>\n",
       "      <td>57</td>\n",
       "      <td>49</td>\n",
       "      <td>66</td>\n",
       "      <td>103</td>\n",
       "      <td>64</td>\n",
       "      <td>106</td>\n",
       "      <td>114</td>\n",
       "      <td>28</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.94</td>\n",
       "      <td>-21.74</td>\n",
       "      <td>-1.64</td>\n",
       "      <td>-4.62</td>\n",
       "      <td>-23.74</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>-5.50</td>\n",
       "      <td>-22.83</td>\n",
       "      <td>-2.74</td>\n",
       "      <td>-5.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class  b1  b2  b3   b4  b5   b6   b7  b8  b9  ...  pred_minus_obs_H_b9  \\\n",
       "0    d   39  36  57   91  59  101   93  27  60  ...                -2.36   \n",
       "1    h   84  30  57  112  51   98   92  26  62  ...                -2.26   \n",
       "2    s   53  25  49   99  51   93   84  26  58  ...                -1.46   \n",
       "3    s   59  26  49  103  47   92   82  25  56  ...                 2.68   \n",
       "4    d   57  49  66  103  64  106  114  28  59  ...                -2.94   \n",
       "\n",
       "   pred_minus_obs_S_b1  pred_minus_obs_S_b2  pred_minus_obs_S_b3  \\\n",
       "0               -18.41                -1.88                -6.43   \n",
       "1               -16.27                -1.95                -6.25   \n",
       "2               -15.92                -1.79                -4.64   \n",
       "3               -13.77                -2.53                -6.34   \n",
       "4               -21.74                -1.64                -4.62   \n",
       "\n",
       "   pred_minus_obs_S_b4  pred_minus_obs_S_b5  pred_minus_obs_S_b6  \\\n",
       "0               -21.03                -1.60                -6.18   \n",
       "1               -18.79                -1.99                -6.18   \n",
       "2               -17.73                -0.48                -4.69   \n",
       "3               -22.03                -2.34                -6.60   \n",
       "4               -23.74                -0.85                -5.50   \n",
       "\n",
       "   pred_minus_obs_S_b7  pred_minus_obs_S_b8  pred_minus_obs_S_b9  \n",
       "0               -22.50                -5.20                -7.86  \n",
       "1               -23.41                -8.87               -10.83  \n",
       "2               -19.97                -4.10                -7.07  \n",
       "3               -27.10                -7.99               -10.81  \n",
       "4               -22.83                -2.74                -5.84  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file without setting any column as the index\n",
    "df = pd.read_csv(\"C:/Users/vedan/OneDrive/Desktop/ForestTypeMapping/forest-type-mapping-ESP32/Data/training.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "084ba978-e57a-43dd-a9f9-b66c88b22be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['class', 'b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7', 'b8', 'b9',\n",
       "       'pred_minus_obs_H_b1', 'pred_minus_obs_H_b2', 'pred_minus_obs_H_b3',\n",
       "       'pred_minus_obs_H_b4', 'pred_minus_obs_H_b5', 'pred_minus_obs_H_b6',\n",
       "       'pred_minus_obs_H_b7', 'pred_minus_obs_H_b8', 'pred_minus_obs_H_b9',\n",
       "       'pred_minus_obs_S_b1', 'pred_minus_obs_S_b2', 'pred_minus_obs_S_b3',\n",
       "       'pred_minus_obs_S_b4', 'pred_minus_obs_S_b5', 'pred_minus_obs_S_b6',\n",
       "       'pred_minus_obs_S_b7', 'pred_minus_obs_S_b8', 'pred_minus_obs_S_b9'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b710e172-2c68-4b61-b01b-48d65c5fd56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'class' column: ['d ' 'h ' 's ' 'o ']\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique values in 'class' column:\", df['class'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72147202-6bf2-45fd-8ee6-ea741705481c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary statistics for numerical columns:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>b8</th>\n",
       "      <th>b9</th>\n",
       "      <th>pred_minus_obs_H_b1</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_minus_obs_H_b9</th>\n",
       "      <th>pred_minus_obs_S_b1</th>\n",
       "      <th>pred_minus_obs_S_b2</th>\n",
       "      <th>pred_minus_obs_S_b3</th>\n",
       "      <th>pred_minus_obs_S_b4</th>\n",
       "      <th>pred_minus_obs_S_b5</th>\n",
       "      <th>pred_minus_obs_S_b6</th>\n",
       "      <th>pred_minus_obs_S_b7</th>\n",
       "      <th>pred_minus_obs_S_b8</th>\n",
       "      <th>pred_minus_obs_S_b9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>198.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>198.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>62.949495</td>\n",
       "      <td>41.020202</td>\n",
       "      <td>63.676768</td>\n",
       "      <td>101.409091</td>\n",
       "      <td>58.732323</td>\n",
       "      <td>100.651515</td>\n",
       "      <td>90.601010</td>\n",
       "      <td>28.691919</td>\n",
       "      <td>61.116162</td>\n",
       "      <td>50.818889</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.594141</td>\n",
       "      <td>-20.037576</td>\n",
       "      <td>-1.007121</td>\n",
       "      <td>-4.355657</td>\n",
       "      <td>-20.996919</td>\n",
       "      <td>-0.973737</td>\n",
       "      <td>-4.597626</td>\n",
       "      <td>-18.840000</td>\n",
       "      <td>-1.570808</td>\n",
       "      <td>-4.155859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.779563</td>\n",
       "      <td>17.832543</td>\n",
       "      <td>17.314545</td>\n",
       "      <td>14.804627</td>\n",
       "      <td>12.392648</td>\n",
       "      <td>11.190314</td>\n",
       "      <td>15.588861</td>\n",
       "      <td>8.977752</td>\n",
       "      <td>9.787158</td>\n",
       "      <td>12.842321</td>\n",
       "      <td>...</td>\n",
       "      <td>9.769193</td>\n",
       "      <td>4.948562</td>\n",
       "      <td>1.783671</td>\n",
       "      <td>2.352311</td>\n",
       "      <td>6.490763</td>\n",
       "      <td>0.702619</td>\n",
       "      <td>1.736712</td>\n",
       "      <td>5.251095</td>\n",
       "      <td>1.807792</td>\n",
       "      <td>1.982423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>7.660000</td>\n",
       "      <td>...</td>\n",
       "      <td>-53.530000</td>\n",
       "      <td>-32.950000</td>\n",
       "      <td>-8.800000</td>\n",
       "      <td>-11.210000</td>\n",
       "      <td>-40.370000</td>\n",
       "      <td>-3.270000</td>\n",
       "      <td>-8.730000</td>\n",
       "      <td>-34.140000</td>\n",
       "      <td>-8.870000</td>\n",
       "      <td>-10.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>92.250000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>40.667500</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.627500</td>\n",
       "      <td>-23.325000</td>\n",
       "      <td>-1.860000</td>\n",
       "      <td>-5.790000</td>\n",
       "      <td>-24.090000</td>\n",
       "      <td>-1.290000</td>\n",
       "      <td>-5.747500</td>\n",
       "      <td>-22.237500</td>\n",
       "      <td>-2.370000</td>\n",
       "      <td>-5.122500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>31.500000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>99.500000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>53.030000</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.255000</td>\n",
       "      <td>-20.020000</td>\n",
       "      <td>-0.970000</td>\n",
       "      <td>-4.350000</td>\n",
       "      <td>-20.465000</td>\n",
       "      <td>-0.945000</td>\n",
       "      <td>-4.540000</td>\n",
       "      <td>-19.200000</td>\n",
       "      <td>-1.420000</td>\n",
       "      <td>-4.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>70.750000</td>\n",
       "      <td>50.750000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>111.750000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>59.920000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247500</td>\n",
       "      <td>-17.787500</td>\n",
       "      <td>-0.042500</td>\n",
       "      <td>-2.882500</td>\n",
       "      <td>-17.955000</td>\n",
       "      <td>-0.642500</td>\n",
       "      <td>-3.617500</td>\n",
       "      <td>-16.227500</td>\n",
       "      <td>-0.655000</td>\n",
       "      <td>-3.105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>105.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>83.320000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.740000</td>\n",
       "      <td>5.130000</td>\n",
       "      <td>12.460000</td>\n",
       "      <td>7.370000</td>\n",
       "      <td>1.880000</td>\n",
       "      <td>3.440000</td>\n",
       "      <td>3.940000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>8.840000</td>\n",
       "      <td>7.790000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               b1          b2          b3          b4          b5          b6  \\\n",
       "count  198.000000  198.000000  198.000000  198.000000  198.000000  198.000000   \n",
       "mean    62.949495   41.020202   63.676768  101.409091   58.732323  100.651515   \n",
       "std     12.779563   17.832543   17.314545   14.804627   12.392648   11.190314   \n",
       "min     34.000000   25.000000   47.000000   54.000000   44.000000   84.000000   \n",
       "25%     54.000000   28.000000   52.000000   92.250000   49.000000   92.000000   \n",
       "50%     60.000000   31.500000   57.000000   99.500000   55.000000   98.000000   \n",
       "75%     70.750000   50.750000   69.000000  111.750000   65.000000  107.000000   \n",
       "max    105.000000  160.000000  196.000000  172.000000   98.000000  136.000000   \n",
       "\n",
       "               b7          b8          b9  pred_minus_obs_H_b1  ...  \\\n",
       "count  198.000000  198.000000  198.000000           198.000000  ...   \n",
       "mean    90.601010   28.691919   61.116162            50.818889  ...   \n",
       "std     15.588861    8.977752    9.787158            12.842321  ...   \n",
       "min     54.000000   21.000000   50.000000             7.660000  ...   \n",
       "25%     80.000000   24.000000   55.000000            40.667500  ...   \n",
       "50%     91.000000   25.000000   58.000000            53.030000  ...   \n",
       "75%    101.000000   27.000000   63.000000            59.920000  ...   \n",
       "max    139.000000   82.000000  109.000000            83.320000  ...   \n",
       "\n",
       "       pred_minus_obs_H_b9  pred_minus_obs_S_b1  pred_minus_obs_S_b2  \\\n",
       "count           198.000000           198.000000           198.000000   \n",
       "mean             -5.594141           -20.037576            -1.007121   \n",
       "std               9.769193             4.948562             1.783671   \n",
       "min             -53.530000           -32.950000            -8.800000   \n",
       "25%              -6.627500           -23.325000            -1.860000   \n",
       "50%              -2.255000           -20.020000            -0.970000   \n",
       "75%               0.247500           -17.787500            -0.042500   \n",
       "max               5.740000             5.130000            12.460000   \n",
       "\n",
       "       pred_minus_obs_S_b3  pred_minus_obs_S_b4  pred_minus_obs_S_b5  \\\n",
       "count           198.000000           198.000000           198.000000   \n",
       "mean             -4.355657           -20.996919            -0.973737   \n",
       "std               2.352311             6.490763             0.702619   \n",
       "min             -11.210000           -40.370000            -3.270000   \n",
       "25%              -5.790000           -24.090000            -1.290000   \n",
       "50%              -4.350000           -20.465000            -0.945000   \n",
       "75%              -2.882500           -17.955000            -0.642500   \n",
       "max               7.370000             1.880000             3.440000   \n",
       "\n",
       "       pred_minus_obs_S_b6  pred_minus_obs_S_b7  pred_minus_obs_S_b8  \\\n",
       "count           198.000000           198.000000           198.000000   \n",
       "mean             -4.597626           -18.840000            -1.570808   \n",
       "std               1.736712             5.251095             1.807792   \n",
       "min              -8.730000           -34.140000            -8.870000   \n",
       "25%              -5.747500           -22.237500            -2.370000   \n",
       "50%              -4.540000           -19.200000            -1.420000   \n",
       "75%              -3.617500           -16.227500            -0.655000   \n",
       "max               3.940000             3.670000             8.840000   \n",
       "\n",
       "       pred_minus_obs_S_b9  \n",
       "count           198.000000  \n",
       "mean             -4.155859  \n",
       "std               1.982423  \n",
       "min             -10.830000  \n",
       "25%              -5.122500  \n",
       "50%              -4.125000  \n",
       "75%              -3.105000  \n",
       "max               7.790000  \n",
       "\n",
       "[8 rows x 27 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get basic statistics for numerical columns\n",
    "print(\"\\nSummary statistics for numerical columns:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b5a54b9-fe85-42f3-952c-75e055cdabf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values in each column:\n",
      "class: 4 unique values\n",
      "b1: 50 unique values\n",
      "b2: 52 unique values\n",
      "b3: 50 unique values\n",
      "b4: 58 unique values\n",
      "b5: 47 unique values\n",
      "b6: 42 unique values\n",
      "b7: 61 unique values\n",
      "b8: 32 unique values\n",
      "b9: 38 unique values\n",
      "pred_minus_obs_H_b1: 191 unique values\n",
      "pred_minus_obs_H_b2: 189 unique values\n",
      "pred_minus_obs_H_b3: 191 unique values\n",
      "pred_minus_obs_H_b4: 193 unique values\n",
      "pred_minus_obs_H_b5: 189 unique values\n",
      "pred_minus_obs_H_b6: 194 unique values\n",
      "pred_minus_obs_H_b7: 195 unique values\n",
      "pred_minus_obs_H_b8: 183 unique values\n",
      "pred_minus_obs_H_b9: 193 unique values\n",
      "pred_minus_obs_S_b1: 183 unique values\n",
      "pred_minus_obs_S_b2: 165 unique values\n",
      "pred_minus_obs_S_b3: 173 unique values\n",
      "pred_minus_obs_S_b4: 185 unique values\n",
      "pred_minus_obs_S_b5: 123 unique values\n",
      "pred_minus_obs_S_b6: 173 unique values\n",
      "pred_minus_obs_S_b7: 182 unique values\n",
      "pred_minus_obs_S_b8: 166 unique values\n",
      "pred_minus_obs_S_b9: 166 unique values\n"
     ]
    }
   ],
   "source": [
    "# Get the unique values in each column to see if there are categorical data\n",
    "print(\"\\nUnique values in each column:\")\n",
    "for column in df.columns:\n",
    "    print(f\"{column}: {df[column].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "74245b51-2c69-4fea-9013-be5f6a32a1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class distribution:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "class\n",
       "s     59\n",
       "d     54\n",
       "h     48\n",
       "o     37\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the distribution of the 'class' column\n",
    "print(\"\\nClass distribution:\")\n",
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3a1bb5-0c74-48b3-9c20-4e37e5923a13",
   "metadata": {},
   "source": [
    "## 2. Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eaefb6aa-7d2a-4c01-998b-708261db33b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"C:/Users/vedan/OneDrive/Desktop/ForestTypeMapping/forest-type-mapping-ESP32/Data/training.csv\")\n",
    "test_df = pd.read_csv(\"C:/Users/vedan/OneDrive/Desktop/ForestTypeMapping/forest-type-mapping-ESP32/Data/testing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd58008c-292a-4d6f-8154-cdfa1d5924df",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2baf29b-89b7-4070-aef9-a2e3b495c00b",
   "metadata": {},
   "source": [
    "### 3.1 Encode the Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2889ef2-5aa6-4f46-a103-3723d270b0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the 'class' column\n",
    "label_encoder = LabelEncoder()\n",
    "train_df['class'] = label_encoder.fit_transform(train_df['class'].str.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f1840b-fbe5-4396-bf1b-c0e90c12db15",
   "metadata": {},
   "source": [
    "### 3.2 Separate Features and Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ccfd3151-dc29-4f70-a29e-5aebc490752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable in training data\n",
    "columns_to_drop = ['class', 'pred_minus_obs_H_b1', 'pred_minus_obs_H_b2', 'pred_minus_obs_H_b3',\n",
    "       'pred_minus_obs_H_b4', 'pred_minus_obs_H_b5', 'pred_minus_obs_H_b6',\n",
    "       'pred_minus_obs_H_b7', 'pred_minus_obs_H_b8', 'pred_minus_obs_H_b9',\n",
    "       'pred_minus_obs_S_b1', 'pred_minus_obs_S_b2', 'pred_minus_obs_S_b3',\n",
    "       'pred_minus_obs_S_b4', 'pred_minus_obs_S_b5', 'pred_minus_obs_S_b6',\n",
    "       'pred_minus_obs_S_b7', 'pred_minus_obs_S_b8', 'pred_minus_obs_S_b9']\n",
    "\n",
    "X = train_df.drop(columns=columns_to_drop)\n",
    "y = train_df['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87556bf-2302-466b-a781-91d2223f6cf8",
   "metadata": {},
   "source": [
    "### 3.3 One-Hot Encoding and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bfe3035d-e5bb-4dd8-8bf9-b56a904be158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding the target variable\n",
    "y = to_categorical(y)\n",
    "\n",
    "# Normalize the feature data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c98ffd-f16e-4199-8ed7-2bc0333ae8eb",
   "metadata": {},
   "source": [
    "### 3.4 Train-Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "62680d74-93fe-47db-b7d5-5b6aa3d93b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c5e0d1-e187-4cd5-abb9-9b1c27774ae3",
   "metadata": {},
   "source": [
    "## 4. Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7c73f532-0823-4f3d-9949-515dfce59663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "DENSE1_SIZE = 16 # Increased size for more capacity\n",
    "DENSE2_SIZE = 8\n",
    "DENSE3_SIZE = 4\n",
    "NUM_OF_EPOCHS = 100  # Increased epochs for better training\n",
    "BATCH_SIZE = 16  # Adjusted batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8eb8b5f-00cc-45fa-a281-9ce6ec028d62",
   "metadata": {},
   "source": [
    "## 5. Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "42d3914e-f93a-4f52-a194-f6745bc324b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedan\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(X_train.shape[1],)))\n",
    "model.add(tf.keras.layers.Dense(DENSE1_SIZE, activation='relu'))\n",
    "# model.add(tf.keras.layers.Dropout(0.3))  # Added dropout for regularization\n",
    "model.add(tf.keras.layers.Dense(DENSE2_SIZE, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(DENSE3_SIZE, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(y.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e0dc0b56-995c-42e2-bba3-d4dc1834e862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m160\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m136\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │              \u001b[38;5;34m36\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │              \u001b[38;5;34m20\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> (1.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m352\u001b[0m (1.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> (1.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m352\u001b[0m (1.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d11e779-906a-440d-a891-388f82fe9bb4",
   "metadata": {},
   "source": [
    "## 6. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fda5a441-1a4e-4630-b375-1d0c51ab3994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.2914 - loss: 1.4384 - val_accuracy: 0.4250 - val_loss: 1.3926\n",
      "Epoch 2/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3942 - loss: 1.4017 - val_accuracy: 0.3750 - val_loss: 1.3311\n",
      "Epoch 3/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4155 - loss: 1.3344 - val_accuracy: 0.5000 - val_loss: 1.2769\n",
      "Epoch 4/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4935 - loss: 1.2769 - val_accuracy: 0.6500 - val_loss: 1.2392\n",
      "Epoch 5/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6216 - loss: 1.2487 - val_accuracy: 0.6750 - val_loss: 1.2001\n",
      "Epoch 6/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5921 - loss: 1.1946 - val_accuracy: 0.7250 - val_loss: 1.1526\n",
      "Epoch 7/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6985 - loss: 1.1372 - val_accuracy: 0.7250 - val_loss: 1.1017\n",
      "Epoch 8/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7249 - loss: 1.0812 - val_accuracy: 0.8000 - val_loss: 1.0493\n",
      "Epoch 9/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7464 - loss: 1.0261 - val_accuracy: 0.8500 - val_loss: 0.9947\n",
      "Epoch 10/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7566 - loss: 0.9726 - val_accuracy: 0.9000 - val_loss: 0.9387\n",
      "Epoch 11/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7620 - loss: 0.9307 - val_accuracy: 0.9250 - val_loss: 0.8813\n",
      "Epoch 12/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8091 - loss: 0.8393 - val_accuracy: 0.9250 - val_loss: 0.8234\n",
      "Epoch 13/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8788 - loss: 0.7739 - val_accuracy: 0.9500 - val_loss: 0.7636\n",
      "Epoch 14/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8270 - loss: 0.7531 - val_accuracy: 0.9500 - val_loss: 0.7045\n",
      "Epoch 15/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8801 - loss: 0.6842 - val_accuracy: 0.9750 - val_loss: 0.6472\n",
      "Epoch 16/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8947 - loss: 0.6289 - val_accuracy: 0.9500 - val_loss: 0.5922\n",
      "Epoch 17/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9075 - loss: 0.5754 - val_accuracy: 0.9500 - val_loss: 0.5415\n",
      "Epoch 18/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9072 - loss: 0.5270 - val_accuracy: 0.9500 - val_loss: 0.4911\n",
      "Epoch 19/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9328 - loss: 0.4630 - val_accuracy: 0.9750 - val_loss: 0.4455\n",
      "Epoch 20/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9253 - loss: 0.4333 - val_accuracy: 0.9750 - val_loss: 0.4061\n",
      "Epoch 21/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9215 - loss: 0.3813 - val_accuracy: 0.9750 - val_loss: 0.3738\n",
      "Epoch 22/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9464 - loss: 0.3644 - val_accuracy: 0.9750 - val_loss: 0.3423\n",
      "Epoch 23/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9423 - loss: 0.3222 - val_accuracy: 0.9750 - val_loss: 0.3157\n",
      "Epoch 24/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9133 - loss: 0.3270 - val_accuracy: 0.9750 - val_loss: 0.2952\n",
      "Epoch 25/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9305 - loss: 0.3082 - val_accuracy: 0.9750 - val_loss: 0.2764\n",
      "Epoch 26/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9313 - loss: 0.2811 - val_accuracy: 0.9750 - val_loss: 0.2603\n",
      "Epoch 27/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9178 - loss: 0.2621 - val_accuracy: 0.9750 - val_loss: 0.2481\n",
      "Epoch 28/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9292 - loss: 0.2552 - val_accuracy: 0.9750 - val_loss: 0.2357\n",
      "Epoch 29/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9026 - loss: 0.2781 - val_accuracy: 0.9750 - val_loss: 0.2293\n",
      "Epoch 30/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9375 - loss: 0.2027 - val_accuracy: 0.9750 - val_loss: 0.2202\n",
      "Epoch 31/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9346 - loss: 0.2100 - val_accuracy: 0.9750 - val_loss: 0.2138\n",
      "Epoch 32/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9177 - loss: 0.2640 - val_accuracy: 0.9750 - val_loss: 0.2075\n",
      "Epoch 33/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9296 - loss: 0.2555 - val_accuracy: 0.9750 - val_loss: 0.2033\n",
      "Epoch 34/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9345 - loss: 0.1890 - val_accuracy: 0.9750 - val_loss: 0.2010\n",
      "Epoch 35/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9415 - loss: 0.1824 - val_accuracy: 0.9750 - val_loss: 0.1972\n",
      "Epoch 36/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9421 - loss: 0.1827 - val_accuracy: 0.9750 - val_loss: 0.1956\n",
      "Epoch 37/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9056 - loss: 0.2400 - val_accuracy: 0.9750 - val_loss: 0.1945\n",
      "Epoch 38/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9351 - loss: 0.1611 - val_accuracy: 0.9750 - val_loss: 0.1926\n",
      "Epoch 39/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9245 - loss: 0.2354 - val_accuracy: 0.9750 - val_loss: 0.1908\n",
      "Epoch 40/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9351 - loss: 0.1938 - val_accuracy: 0.9750 - val_loss: 0.1901\n",
      "Epoch 41/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9438 - loss: 0.2120 - val_accuracy: 0.9750 - val_loss: 0.1921\n",
      "Epoch 42/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9590 - loss: 0.1155 - val_accuracy: 0.9750 - val_loss: 0.1907\n",
      "Epoch 43/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9537 - loss: 0.1536 - val_accuracy: 0.9750 - val_loss: 0.1905\n",
      "Epoch 44/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9406 - loss: 0.1713 - val_accuracy: 0.9750 - val_loss: 0.1922\n",
      "Epoch 45/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9660 - loss: 0.1259 - val_accuracy: 0.9750 - val_loss: 0.1917\n",
      "Epoch 46/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9601 - loss: 0.1318 - val_accuracy: 0.9750 - val_loss: 0.1906\n",
      "Epoch 47/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9463 - loss: 0.1834 - val_accuracy: 0.9750 - val_loss: 0.1921\n",
      "Epoch 48/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9535 - loss: 0.1384 - val_accuracy: 0.9750 - val_loss: 0.1925\n",
      "Epoch 49/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9372 - loss: 0.2017 - val_accuracy: 0.9750 - val_loss: 0.1925\n",
      "Epoch 50/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9372 - loss: 0.2253 - val_accuracy: 0.9750 - val_loss: 0.1949\n",
      "Epoch 51/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9390 - loss: 0.1428 - val_accuracy: 0.9750 - val_loss: 0.1961\n",
      "Epoch 52/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9733 - loss: 0.1104 - val_accuracy: 0.9750 - val_loss: 0.1968\n",
      "Epoch 53/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9528 - loss: 0.1665 - val_accuracy: 0.9750 - val_loss: 0.1980\n",
      "Epoch 54/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9470 - loss: 0.1766 - val_accuracy: 0.9750 - val_loss: 0.1999\n",
      "Epoch 55/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9510 - loss: 0.1565 - val_accuracy: 0.9750 - val_loss: 0.2006\n",
      "Epoch 56/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9430 - loss: 0.1536 - val_accuracy: 0.9500 - val_loss: 0.2027\n",
      "Epoch 57/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9599 - loss: 0.1446 - val_accuracy: 0.9500 - val_loss: 0.2036\n",
      "Epoch 58/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9439 - loss: 0.1905 - val_accuracy: 0.9500 - val_loss: 0.2040\n",
      "Epoch 59/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9306 - loss: 0.1741 - val_accuracy: 0.9500 - val_loss: 0.2017\n",
      "Epoch 60/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9390 - loss: 0.1741 - val_accuracy: 0.9500 - val_loss: 0.2052\n",
      "Epoch 61/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9476 - loss: 0.1641 - val_accuracy: 0.9500 - val_loss: 0.2060\n",
      "Epoch 62/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9691 - loss: 0.1082 - val_accuracy: 0.9500 - val_loss: 0.2059\n",
      "Epoch 63/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9704 - loss: 0.1047 - val_accuracy: 0.9500 - val_loss: 0.2078\n",
      "Epoch 64/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9397 - loss: 0.1896 - val_accuracy: 0.9500 - val_loss: 0.2098\n",
      "Epoch 65/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9547 - loss: 0.1442 - val_accuracy: 0.9500 - val_loss: 0.2088\n",
      "Epoch 66/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9502 - loss: 0.1567 - val_accuracy: 0.9500 - val_loss: 0.2115\n",
      "Epoch 67/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9425 - loss: 0.1640 - val_accuracy: 0.9500 - val_loss: 0.2135\n",
      "Epoch 68/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9319 - loss: 0.2072 - val_accuracy: 0.9500 - val_loss: 0.2140\n",
      "Epoch 69/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9458 - loss: 0.1394 - val_accuracy: 0.9500 - val_loss: 0.2138\n",
      "Epoch 70/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9564 - loss: 0.1271 - val_accuracy: 0.9500 - val_loss: 0.2181\n",
      "Epoch 71/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9593 - loss: 0.1262 - val_accuracy: 0.9500 - val_loss: 0.2187\n",
      "Epoch 72/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9322 - loss: 0.1814 - val_accuracy: 0.9500 - val_loss: 0.2181\n",
      "Epoch 73/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9459 - loss: 0.1766 - val_accuracy: 0.9500 - val_loss: 0.2190\n",
      "Epoch 74/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9536 - loss: 0.1666 - val_accuracy: 0.9500 - val_loss: 0.2213\n",
      "Epoch 75/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9438 - loss: 0.1602 - val_accuracy: 0.9500 - val_loss: 0.2247\n",
      "Epoch 76/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9618 - loss: 0.1223 - val_accuracy: 0.9500 - val_loss: 0.2252\n",
      "Epoch 77/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9639 - loss: 0.1078 - val_accuracy: 0.9500 - val_loss: 0.2261\n",
      "Epoch 78/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9313 - loss: 0.1366 - val_accuracy: 0.9500 - val_loss: 0.2276\n",
      "Epoch 79/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9746 - loss: 0.0901 - val_accuracy: 0.9500 - val_loss: 0.2283\n",
      "Epoch 80/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9483 - loss: 0.1398 - val_accuracy: 0.9500 - val_loss: 0.2286\n",
      "Epoch 81/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9610 - loss: 0.1245 - val_accuracy: 0.9500 - val_loss: 0.2312\n",
      "Epoch 82/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9565 - loss: 0.1305 - val_accuracy: 0.9500 - val_loss: 0.2332\n",
      "Epoch 83/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9605 - loss: 0.1345 - val_accuracy: 0.9500 - val_loss: 0.2345\n",
      "Epoch 84/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9690 - loss: 0.1038 - val_accuracy: 0.9500 - val_loss: 0.2382\n",
      "Epoch 85/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9569 - loss: 0.1281 - val_accuracy: 0.9500 - val_loss: 0.2407\n",
      "Epoch 86/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9616 - loss: 0.1016 - val_accuracy: 0.9500 - val_loss: 0.2403\n",
      "Epoch 87/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9372 - loss: 0.1630 - val_accuracy: 0.9500 - val_loss: 0.2423\n",
      "Epoch 88/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9651 - loss: 0.1248 - val_accuracy: 0.9500 - val_loss: 0.2447\n",
      "Epoch 89/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9669 - loss: 0.1111 - val_accuracy: 0.9500 - val_loss: 0.2462\n",
      "Epoch 90/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9651 - loss: 0.1270 - val_accuracy: 0.9500 - val_loss: 0.2483\n",
      "Epoch 91/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9618 - loss: 0.0922 - val_accuracy: 0.9500 - val_loss: 0.2498\n",
      "Epoch 92/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9473 - loss: 0.1470 - val_accuracy: 0.9500 - val_loss: 0.2519\n",
      "Epoch 93/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9591 - loss: 0.1090 - val_accuracy: 0.9500 - val_loss: 0.2532\n",
      "Epoch 94/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9634 - loss: 0.1176 - val_accuracy: 0.9500 - val_loss: 0.2544\n",
      "Epoch 95/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9551 - loss: 0.1254 - val_accuracy: 0.9500 - val_loss: 0.2541\n",
      "Epoch 96/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9572 - loss: 0.1471 - val_accuracy: 0.9500 - val_loss: 0.2573\n",
      "Epoch 97/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9624 - loss: 0.1088 - val_accuracy: 0.9500 - val_loss: 0.2566\n",
      "Epoch 98/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9463 - loss: 0.1462 - val_accuracy: 0.9500 - val_loss: 0.2605\n",
      "Epoch 99/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9732 - loss: 0.0956 - val_accuracy: 0.9500 - val_loss: 0.2619\n",
      "Epoch 100/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9552 - loss: 0.1093 - val_accuracy: 0.9500 - val_loss: 0.2642\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=NUM_OF_EPOCHS, \n",
    "                    verbose=1, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d1bf35-8063-4a60-a9ee-42369ed726d8",
   "metadata": {},
   "source": [
    "## 7. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "07a073c1-2cd7-4ff5-8d28-bbedd9df2f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 96.20%\n",
      "Validation (Testing) Accuracy: 95.00%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the training data\n",
    "train_loss, train_accuracy = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Evaluate the model on the validation (testing) data\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f\"Validation (Testing) Accuracy: {val_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6260016f-9df7-4cc4-a409-aba9a7354689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 80.92%\n"
     ]
    }
   ],
   "source": [
    "# Ensure labels are consistent by applying LabelEncoder to known classes only\n",
    "test_df['class'] = label_encoder.transform(test_df['class'].str.strip())\n",
    "\n",
    "# Separate features and target variable in testing data\n",
    "X_test = test_df.drop(columns=columns_to_drop)\n",
    "y_test = test_df['class']\n",
    "\n",
    "# One-hot encode the target variable in testing data\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Normalize the feature data in the testing set\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Evaluate the model on the separate testing data\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print(f\"Testing Accuracy: {test_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78004cb-7779-4df7-ae55-4833b42bc97b",
   "metadata": {},
   "source": [
    "## 8. Model Conversion to TensorFlow Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d53a89d0-abaf-4620-ab54-9cbb2fcaf30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object representative_dataset at 0x000001CB910D6190>\n"
     ]
    }
   ],
   "source": [
    "def representative_dataset():\n",
    "    for _ in range(100):\n",
    "        data = X_test_scaled.astype(np.float32)\n",
    "        yield [data]\n",
    "\n",
    "print(representative_dataset())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "147fe252-97da-4576-9da5-6ebd45eaf6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save('ForestTypeMappingModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "192875dc-2f77-40e2-80cb-dac9a893248a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\vedan\\AppData\\Local\\Temp\\tmpvumh3pdb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\vedan\\AppData\\Local\\Temp\\tmpvumh3pdb\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\vedan\\AppData\\Local\\Temp\\tmpvumh3pdb'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 9), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1973823267152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1973823266384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1973823266576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1973823266000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1973823269072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1973823269648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1973823268496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1973823270800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "Model has been converted and saved as 'ForestTypeMappingModel.tflite'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedan\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\lite\\python\\convert.py:983: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Convert the model to TensorFlow Lite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# Apply optimizations (optional)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Representative dataset for quantization (provide a function for this)\n",
    "def representative_dataset():\n",
    "    for _ in range(100):\n",
    "        yield [X_train.astype(np.float32)]  # Use training data or any relevant subset\n",
    "\n",
    "converter.representative_dataset = representative_dataset\n",
    "\n",
    "# Convert the model\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the converted model\n",
    "with open('ForestTypeMappingModel.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"Model has been converted and saved as 'ForestTypeMappingModel.tflite'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48014ac2-296a-4dab-8e96-58f1d4c3dcd4",
   "metadata": {},
   "source": [
    "## 9. Load and Test TFLite Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d91d27c1-13b6-413d-a082-a6f49d7919ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input details:\n",
      " [{'name': 'serving_default_keras_tensor:0', 'index': 0, 'shape': array([1, 9]), 'shape_signature': array([-1,  9]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "Output details:\n",
      " [{'name': 'StatefulPartitionedCall_1:0', 'index': 17, 'shape': array([1, 4]), 'shape_signature': array([-1,  4]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "# Load the TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=\"ForestTypeMappingModel.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors details.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print('Input details:\\n', input_details)\n",
    "print('Output details:\\n', output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f059aad3-379a-44d1-81ae-4473250a8595",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Input Inference Output:\n",
      "[[0.015625   0.015625   0.96484375 0.00390625]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step\n",
      "Keras Model Prediction Output for Random Input:\n",
      "[[0.01600724 0.01638388 0.96319747 0.00441144]]\n"
     ]
    }
   ],
   "source": [
    "# Test the model on random input data.\n",
    "input_shape = input_details[0]['shape']\n",
    "random_input_data = np.random.random_sample(input_shape).astype(np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], random_input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get the output tensor.\n",
    "random_output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(\"Random Input Inference Output:\")\n",
    "print(random_output_data)\n",
    "\n",
    "# Verify if the same random input data is given to the original model, what is the output\n",
    "keras_output = model.predict(random_input_data)\n",
    "print(\"Keras Model Prediction Output for Random Input:\")\n",
    "print(keras_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "70a10fd3-40cc-4ab5-96d3-a269d159d326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled Input: [[-0.93741743  0.89837465  0.77143262 -0.77259708  2.44858083  2.00219009\n",
      "   0.41152528  2.04444149  2.24164257]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedan\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Suppose scaler is already fitted on the training data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)  # Where X is the feature set from the training data\n",
    "\n",
    "# Sample input\n",
    "input_data = np.array([51 , 57  ,77 ,  90  ,89  ,123 ,  97 , 47,  83]).reshape(1, -1)\n",
    "\n",
    "# Scale the input\n",
    "scaled_input = scaler.transform(input_data)\n",
    "print(\"Scaled Input:\", scaled_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e2cb5400-dac7-434a-94a6-a2c4e236c106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume we have the label encoder used during training\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.classes_ = np.array(['d','h','o','s'])  # Replace with your actual class names\n",
    "\n",
    "# Load the TFLite model and allocate tensors\n",
    "interpreter = tf.lite.Interpreter(model_path=\"ForestTypeMappingModel.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "80a6577e-f610-4a37-8bd1-995c9b6feaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output Probabilities: [0.9765625  0.         0.00390625 0.01953125]\n",
      "Predicted Forest Class: d\n"
     ]
    }
   ],
   "source": [
    "# Define a sample input (e.g., one row of normalized test data)\n",
    "# Adjust values as needed for meaningful test cases\n",
    "specific_input_data = np.array([[-1.8787969 , -0.28223274, -0.3865936 , -0.7048794, 0.02165439 , 0.03122059,\n",
    "   0.15428138 ,-0.18893459 ,-0.11433257]], dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], specific_input_data)\n",
    "\n",
    "# Run inference\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get the output tensor (predicted probabilities)\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])[0]\n",
    "print(\"Model Output Probabilities:\", output_data)\n",
    "\n",
    "# Get the index of the highest probability, which corresponds to the predicted class\n",
    "predicted_class_index = np.argmax(output_data)\n",
    "\n",
    "# Decode the class index back to the original class label\n",
    "predicted_class_label = label_encoder.inverse_transform([predicted_class_index])[0]\n",
    "print(\"Predicted Forest Class:\", predicted_class_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7a832ff9-cad9-436f-bb41-c6e9eb1e4d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output Probabilities: [0.00390625 0.97265625 0.         0.0234375 ]\n",
      "Predicted Forest Class: h\n"
     ]
    }
   ],
   "source": [
    "# Define a sample input (e.g., one row of normalized test data)\n",
    "# Adjust values as needed for meaningful test cases\n",
    "specific_input_data = np.array([[ 1.72982439, -0.73198794, -0.44449491,  1.25893309 ,-0.54462844 ,-0.23754798\n",
    "  , 0.66876918, -0.18893459,  0.39783594]], dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], specific_input_data)\n",
    "\n",
    "# Run inference\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get the output tensor (predicted probabilities)\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])[0]\n",
    "print(\"Model Output Probabilities:\", output_data)\n",
    "\n",
    "# Get the index of the highest probability, which corresponds to the predicted class\n",
    "predicted_class_index = np.argmax(output_data)\n",
    "\n",
    "# Decode the class index back to the original class label\n",
    "predicted_class_label = label_encoder.inverse_transform([predicted_class_index])[0]\n",
    "print(\"Predicted Forest Class:\", predicted_class_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c004b881-b11d-4d13-87d1-ce4b4fb52b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output Probabilities: [0.      0.03125 0.      0.96875]\n",
      "Predicted Forest Class: s\n"
     ]
    }
   ],
   "source": [
    "# Define a sample input (e.g., one row of normalized test data)\n",
    "# Adjust values as needed for meaningful test cases\n",
    "specific_input_data = np.array([[-0.54517599 ,-0.67576854, -0.79190278, -0.56944406, -0.62552599, -0.59590607,\n",
    "  -0.87469423, -0.3006034 , -0.31919997]], dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], specific_input_data)\n",
    "\n",
    "# Run inference\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get the output tensor (predicted probabilities)\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])[0]\n",
    "print(\"Model Output Probabilities:\", output_data)\n",
    "\n",
    "# Get the index of the highest probability, which corresponds to the predicted class\n",
    "predicted_class_index = np.argmax(output_data)\n",
    "\n",
    "# Decode the class index back to the original class label\n",
    "predicted_class_label = label_encoder.inverse_transform([predicted_class_index])[0]\n",
    "print(\"Predicted Forest Class:\", predicted_class_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d917db96-a60b-4842-a0b6-24cc49912532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Keras Model Output (Probabilities): [[7.16674782e-04 1.19697856e-04 9.99148369e-01 1.52321336e-05]]\n",
      "Keras Model Predicted Class: 2\n",
      "Keras Model Predicted Forest Type: o\n",
      "TFLite Model Output (Probabilities): [0.         0.         0.99609375 0.        ]\n",
      "TFLite Model Predicted Class: 2\n",
      "TFLite Model Predicted Forest Type: o\n"
     ]
    }
   ],
   "source": [
    "# Define the specific input data\n",
    "specific_input_data = np.array([[-0.93741743, 0.89837465, 0.77143262, -0.77259708, \n",
    "                                 2.44858083, 2.00219009, 0.41152528, 2.04444149, \n",
    "                                 2.24164257]], dtype=np.float32)\n",
    "\n",
    "# Predict with the original Keras model\n",
    "keras_output = model.predict(specific_input_data)\n",
    "print(\"Keras Model Output (Probabilities):\", keras_output)\n",
    "\n",
    "# Get the predicted class for the Keras model output\n",
    "keras_predicted_class = np.argmax(keras_output)\n",
    "print(\"Keras Model Predicted Class:\", keras_predicted_class)\n",
    "print(\"Keras Model Predicted Forest Type:\", label_encoder.inverse_transform([keras_predicted_class])[0])\n",
    "\n",
    "# Set the input for the TFLite interpreter\n",
    "interpreter.set_tensor(input_details[0]['index'], specific_input_data)\n",
    "\n",
    "# Invoke the TFLite interpreter\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get the output from the TFLite model\n",
    "tflite_output = interpreter.get_tensor(output_details[0]['index'])[0]\n",
    "print(\"TFLite Model Output (Probabilities):\", tflite_output)\n",
    "\n",
    "# Get the predicted class for the TFLite model output\n",
    "tflite_predicted_class = np.argmax(tflite_output)\n",
    "print(\"TFLite Model Predicted Class:\", tflite_predicted_class)\n",
    "print(\"TFLite Model Predicted Forest Type:\", label_encoder.inverse_transform([tflite_predicted_class])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9797ecc6-7de5-4758-b2d6-7614aef416e8",
   "metadata": {},
   "source": [
    "## 10. Generating the Header File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "45d29b3c-eca5-4f3b-98b2-a466bf3316e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model data was generated on: Tue Oct 29 22:38:08 2024\n",
      "Tools used: Python: 3.12.4 | packaged by Anaconda, Inc. | (main, Jun 18 2024, 15:03:56) [MSC v.1929 64 bit (AMD64)] \n",
      " Numpy: 1.26.4 \n",
      " TensorFlow: 2.17.0 \n",
      " Keras:  3.5.0 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to convert some hex values into an array for C programming\n",
    "def hex_to_c_array(hex_data, var_name):\n",
    "    c_str = \"\"\n",
    "\n",
    "    # Create header guard\n",
    "    c_str += '#ifndef ' + var_name.upper() + '_H\\n'\n",
    "    c_str += \"#define \" + var_name.upper() + '_H\\n\\n'\n",
    "\n",
    "    c_str += \"/*\\n Author: Mouli Sankaran \\n\"\n",
    "    c_str += \" CAUTION: This is an auto generated file.\\n DO NOT EDIT OR MAKE ANY CHANGES TO it.\\n\"\n",
    "\n",
    "    # Time stamping of this model data in the generated file\n",
    "    localtime = time.asctime(time.localtime(time.time()))\n",
    "    c_str += \" This model data was generated on \" + localtime + '\\n\\n'\n",
    "    print(\"This model data was generated on:\", localtime)\n",
    "\n",
    "    # Add information about the versions of tools and packages used in generating this header file\n",
    "    c_str += \" Tools used:\\n Python: \" + str(sys.version) + \"\\n Numpy: \" + str(np.version.version) + \\\n",
    "             \"\\n TensorFlow: \" + str(tf.__version__) + \"\\n Keras: \" + str(tf.keras.__version__) + \"\\n\\n\"\n",
    "    print(\"Tools used: Python:\", sys.version, \"\\n Numpy:\", np.version.version, \\\n",
    "          \"\\n TensorFlow:\", tf.__version__, \"\\n Keras: \", tf.keras.__version__, \"\\n\\n\")\n",
    "\n",
    "    # Training details of the model\n",
    "    c_str += ' Model details are:\\n'\n",
    "    c_str += ' NUM_OF_EPOCHS = ' + str(NUM_OF_EPOCHS) + '\\n'\n",
    "    c_str += ' BATCH_SIZE    = ' + str(BATCH_SIZE) + '\\n*/\\n'\n",
    "    \n",
    "    # Generate 'C' constants for the no. of nodes in each layer\n",
    "    c_str += '\\nconst int ' + 'DENSE1_SIZE' + ' = ' + str(DENSE1_SIZE) + ';\\n'\n",
    "    c_str += 'const int ' + 'DENSE2_SIZE' + ' = ' + str(DENSE2_SIZE) + ';\\n'      \n",
    "    \n",
    "    # Add array length at the top of the file\n",
    "    c_str += '\\nconst unsigned int ' + var_name + '_len = ' + str(len(hex_data)) + ';\\n'\n",
    "\n",
    "    # Declare C variable\n",
    "    c_str += 'alignas(8) const unsigned char ' + var_name + '[] = {'\n",
    "    hex_array = []\n",
    "    for i, val in enumerate(hex_data):\n",
    "        # Construct string from hex\n",
    "        hex_str = format(val, '#04x')\n",
    "\n",
    "        # Add formatting so each line stays within 80 characters\n",
    "        if (i + 1) < len(hex_data):\n",
    "            hex_str += ','\n",
    "        if (i + 1) % 12 == 0:\n",
    "            hex_str += '\\n'\n",
    "        hex_array.append(hex_str)\n",
    "\n",
    "    # Add closing brace\n",
    "    c_str += '\\n' + format(''.join(hex_array)) + '\\n};\\n\\n'\n",
    "\n",
    "    # Close out header guard\n",
    "    c_str += '#endif //' + var_name.upper() + '_H'\n",
    "\n",
    "    return c_str\n",
    "\n",
    "# Assuming tflite_model is your TensorFlow Lite model\n",
    "# Write TFLite model to a C source (or header) file\n",
    "with open(\"forest_model_esp32.h\", 'w') as file:\n",
    "    file.write(hex_to_c_array(tflite_model, \"forest_model_esp32\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
