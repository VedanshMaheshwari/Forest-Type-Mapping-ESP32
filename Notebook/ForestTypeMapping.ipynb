{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6e6e5303-8244-48aa-bddf-3ba71849f040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>b8</th>\n",
       "      <th>b9</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_minus_obs_H_b9</th>\n",
       "      <th>pred_minus_obs_S_b1</th>\n",
       "      <th>pred_minus_obs_S_b2</th>\n",
       "      <th>pred_minus_obs_S_b3</th>\n",
       "      <th>pred_minus_obs_S_b4</th>\n",
       "      <th>pred_minus_obs_S_b5</th>\n",
       "      <th>pred_minus_obs_S_b6</th>\n",
       "      <th>pred_minus_obs_S_b7</th>\n",
       "      <th>pred_minus_obs_S_b8</th>\n",
       "      <th>pred_minus_obs_S_b9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d</td>\n",
       "      <td>39</td>\n",
       "      <td>36</td>\n",
       "      <td>57</td>\n",
       "      <td>91</td>\n",
       "      <td>59</td>\n",
       "      <td>101</td>\n",
       "      <td>93</td>\n",
       "      <td>27</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.36</td>\n",
       "      <td>-18.41</td>\n",
       "      <td>-1.88</td>\n",
       "      <td>-6.43</td>\n",
       "      <td>-21.03</td>\n",
       "      <td>-1.60</td>\n",
       "      <td>-6.18</td>\n",
       "      <td>-22.50</td>\n",
       "      <td>-5.20</td>\n",
       "      <td>-7.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>h</td>\n",
       "      <td>84</td>\n",
       "      <td>30</td>\n",
       "      <td>57</td>\n",
       "      <td>112</td>\n",
       "      <td>51</td>\n",
       "      <td>98</td>\n",
       "      <td>92</td>\n",
       "      <td>26</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.26</td>\n",
       "      <td>-16.27</td>\n",
       "      <td>-1.95</td>\n",
       "      <td>-6.25</td>\n",
       "      <td>-18.79</td>\n",
       "      <td>-1.99</td>\n",
       "      <td>-6.18</td>\n",
       "      <td>-23.41</td>\n",
       "      <td>-8.87</td>\n",
       "      <td>-10.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s</td>\n",
       "      <td>53</td>\n",
       "      <td>25</td>\n",
       "      <td>49</td>\n",
       "      <td>99</td>\n",
       "      <td>51</td>\n",
       "      <td>93</td>\n",
       "      <td>84</td>\n",
       "      <td>26</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.46</td>\n",
       "      <td>-15.92</td>\n",
       "      <td>-1.79</td>\n",
       "      <td>-4.64</td>\n",
       "      <td>-17.73</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>-4.69</td>\n",
       "      <td>-19.97</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>-7.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s</td>\n",
       "      <td>59</td>\n",
       "      <td>26</td>\n",
       "      <td>49</td>\n",
       "      <td>103</td>\n",
       "      <td>47</td>\n",
       "      <td>92</td>\n",
       "      <td>82</td>\n",
       "      <td>25</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>2.68</td>\n",
       "      <td>-13.77</td>\n",
       "      <td>-2.53</td>\n",
       "      <td>-6.34</td>\n",
       "      <td>-22.03</td>\n",
       "      <td>-2.34</td>\n",
       "      <td>-6.60</td>\n",
       "      <td>-27.10</td>\n",
       "      <td>-7.99</td>\n",
       "      <td>-10.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d</td>\n",
       "      <td>57</td>\n",
       "      <td>49</td>\n",
       "      <td>66</td>\n",
       "      <td>103</td>\n",
       "      <td>64</td>\n",
       "      <td>106</td>\n",
       "      <td>114</td>\n",
       "      <td>28</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.94</td>\n",
       "      <td>-21.74</td>\n",
       "      <td>-1.64</td>\n",
       "      <td>-4.62</td>\n",
       "      <td>-23.74</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>-5.50</td>\n",
       "      <td>-22.83</td>\n",
       "      <td>-2.74</td>\n",
       "      <td>-5.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class  b1  b2  b3   b4  b5   b6   b7  b8  b9  ...  pred_minus_obs_H_b9  \\\n",
       "0    d   39  36  57   91  59  101   93  27  60  ...                -2.36   \n",
       "1    h   84  30  57  112  51   98   92  26  62  ...                -2.26   \n",
       "2    s   53  25  49   99  51   93   84  26  58  ...                -1.46   \n",
       "3    s   59  26  49  103  47   92   82  25  56  ...                 2.68   \n",
       "4    d   57  49  66  103  64  106  114  28  59  ...                -2.94   \n",
       "\n",
       "   pred_minus_obs_S_b1  pred_minus_obs_S_b2  pred_minus_obs_S_b3  \\\n",
       "0               -18.41                -1.88                -6.43   \n",
       "1               -16.27                -1.95                -6.25   \n",
       "2               -15.92                -1.79                -4.64   \n",
       "3               -13.77                -2.53                -6.34   \n",
       "4               -21.74                -1.64                -4.62   \n",
       "\n",
       "   pred_minus_obs_S_b4  pred_minus_obs_S_b5  pred_minus_obs_S_b6  \\\n",
       "0               -21.03                -1.60                -6.18   \n",
       "1               -18.79                -1.99                -6.18   \n",
       "2               -17.73                -0.48                -4.69   \n",
       "3               -22.03                -2.34                -6.60   \n",
       "4               -23.74                -0.85                -5.50   \n",
       "\n",
       "   pred_minus_obs_S_b7  pred_minus_obs_S_b8  pred_minus_obs_S_b9  \n",
       "0               -22.50                -5.20                -7.86  \n",
       "1               -23.41                -8.87               -10.83  \n",
       "2               -19.97                -4.10                -7.07  \n",
       "3               -27.10                -7.99               -10.81  \n",
       "4               -22.83                -2.74                -5.84  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file without setting any column as the index\n",
    "df = pd.read_csv(\"training.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "084ba978-e57a-43dd-a9f9-b66c88b22be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['class', 'b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7', 'b8', 'b9',\n",
       "       'pred_minus_obs_H_b1', 'pred_minus_obs_H_b2', 'pred_minus_obs_H_b3',\n",
       "       'pred_minus_obs_H_b4', 'pred_minus_obs_H_b5', 'pred_minus_obs_H_b6',\n",
       "       'pred_minus_obs_H_b7', 'pred_minus_obs_H_b8', 'pred_minus_obs_H_b9',\n",
       "       'pred_minus_obs_S_b1', 'pred_minus_obs_S_b2', 'pred_minus_obs_S_b3',\n",
       "       'pred_minus_obs_S_b4', 'pred_minus_obs_S_b5', 'pred_minus_obs_S_b6',\n",
       "       'pred_minus_obs_S_b7', 'pred_minus_obs_S_b8', 'pred_minus_obs_S_b9'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b710e172-2c68-4b61-b01b-48d65c5fd56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'class' column: ['d ' 'h ' 's ' 'o ']\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique values in 'class' column:\", df['class'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "72147202-6bf2-45fd-8ee6-ea741705481c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary statistics for numerical columns:\n",
      "               b1          b2          b3          b4          b5          b6  \\\n",
      "count  198.000000  198.000000  198.000000  198.000000  198.000000  198.000000   \n",
      "mean    62.949495   41.020202   63.676768  101.409091   58.732323  100.651515   \n",
      "std     12.779563   17.832543   17.314545   14.804627   12.392648   11.190314   \n",
      "min     34.000000   25.000000   47.000000   54.000000   44.000000   84.000000   \n",
      "25%     54.000000   28.000000   52.000000   92.250000   49.000000   92.000000   \n",
      "50%     60.000000   31.500000   57.000000   99.500000   55.000000   98.000000   \n",
      "75%     70.750000   50.750000   69.000000  111.750000   65.000000  107.000000   \n",
      "max    105.000000  160.000000  196.000000  172.000000   98.000000  136.000000   \n",
      "\n",
      "               b7          b8          b9  pred_minus_obs_H_b1  ...  \\\n",
      "count  198.000000  198.000000  198.000000           198.000000  ...   \n",
      "mean    90.601010   28.691919   61.116162            50.818889  ...   \n",
      "std     15.588861    8.977752    9.787158            12.842321  ...   \n",
      "min     54.000000   21.000000   50.000000             7.660000  ...   \n",
      "25%     80.000000   24.000000   55.000000            40.667500  ...   \n",
      "50%     91.000000   25.000000   58.000000            53.030000  ...   \n",
      "75%    101.000000   27.000000   63.000000            59.920000  ...   \n",
      "max    139.000000   82.000000  109.000000            83.320000  ...   \n",
      "\n",
      "       pred_minus_obs_H_b9  pred_minus_obs_S_b1  pred_minus_obs_S_b2  \\\n",
      "count           198.000000           198.000000           198.000000   \n",
      "mean             -5.594141           -20.037576            -1.007121   \n",
      "std               9.769193             4.948562             1.783671   \n",
      "min             -53.530000           -32.950000            -8.800000   \n",
      "25%              -6.627500           -23.325000            -1.860000   \n",
      "50%              -2.255000           -20.020000            -0.970000   \n",
      "75%               0.247500           -17.787500            -0.042500   \n",
      "max               5.740000             5.130000            12.460000   \n",
      "\n",
      "       pred_minus_obs_S_b3  pred_minus_obs_S_b4  pred_minus_obs_S_b5  \\\n",
      "count           198.000000           198.000000           198.000000   \n",
      "mean             -4.355657           -20.996919            -0.973737   \n",
      "std               2.352311             6.490763             0.702619   \n",
      "min             -11.210000           -40.370000            -3.270000   \n",
      "25%              -5.790000           -24.090000            -1.290000   \n",
      "50%              -4.350000           -20.465000            -0.945000   \n",
      "75%              -2.882500           -17.955000            -0.642500   \n",
      "max               7.370000             1.880000             3.440000   \n",
      "\n",
      "       pred_minus_obs_S_b6  pred_minus_obs_S_b7  pred_minus_obs_S_b8  \\\n",
      "count           198.000000           198.000000           198.000000   \n",
      "mean             -4.597626           -18.840000            -1.570808   \n",
      "std               1.736712             5.251095             1.807792   \n",
      "min              -8.730000           -34.140000            -8.870000   \n",
      "25%              -5.747500           -22.237500            -2.370000   \n",
      "50%              -4.540000           -19.200000            -1.420000   \n",
      "75%              -3.617500           -16.227500            -0.655000   \n",
      "max               3.940000             3.670000             8.840000   \n",
      "\n",
      "       pred_minus_obs_S_b9  \n",
      "count           198.000000  \n",
      "mean             -4.155859  \n",
      "std               1.982423  \n",
      "min             -10.830000  \n",
      "25%              -5.122500  \n",
      "50%              -4.125000  \n",
      "75%              -3.105000  \n",
      "max               7.790000  \n",
      "\n",
      "[8 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "# Get basic statistics for numerical columns\n",
    "print(\"\\nSummary statistics for numerical columns:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2b5a54b9-fe85-42f3-952c-75e055cdabf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values in each column:\n",
      "class: 4 unique values\n",
      "b1: 50 unique values\n",
      "b2: 52 unique values\n",
      "b3: 50 unique values\n",
      "b4: 58 unique values\n",
      "b5: 47 unique values\n",
      "b6: 42 unique values\n",
      "b7: 61 unique values\n",
      "b8: 32 unique values\n",
      "b9: 38 unique values\n",
      "pred_minus_obs_H_b1: 191 unique values\n",
      "pred_minus_obs_H_b2: 189 unique values\n",
      "pred_minus_obs_H_b3: 191 unique values\n",
      "pred_minus_obs_H_b4: 193 unique values\n",
      "pred_minus_obs_H_b5: 189 unique values\n",
      "pred_minus_obs_H_b6: 194 unique values\n",
      "pred_minus_obs_H_b7: 195 unique values\n",
      "pred_minus_obs_H_b8: 183 unique values\n",
      "pred_minus_obs_H_b9: 193 unique values\n",
      "pred_minus_obs_S_b1: 183 unique values\n",
      "pred_minus_obs_S_b2: 165 unique values\n",
      "pred_minus_obs_S_b3: 173 unique values\n",
      "pred_minus_obs_S_b4: 185 unique values\n",
      "pred_minus_obs_S_b5: 123 unique values\n",
      "pred_minus_obs_S_b6: 173 unique values\n",
      "pred_minus_obs_S_b7: 182 unique values\n",
      "pred_minus_obs_S_b8: 166 unique values\n",
      "pred_minus_obs_S_b9: 166 unique values\n"
     ]
    }
   ],
   "source": [
    "# Get the unique values in each column to see if there are categorical data\n",
    "print(\"\\nUnique values in each column:\")\n",
    "for column in df.columns:\n",
    "    print(f\"{column}: {df[column].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "74245b51-2c69-4fea-9013-be5f6a32a1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class distribution:\n",
      "class\n",
      "s     59\n",
      "d     54\n",
      "h     48\n",
      "o     37\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the distribution of the 'class' column\n",
    "print(\"\\nClass distribution:\")\n",
    "print(df['class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a2889ef2-5aa6-4f46-a103-3723d270b0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedan\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ flatten_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ flatten_8 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m160\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m136\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │              \u001b[38;5;34m36\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">332</span> (1.30 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m332\u001b[0m (1.30 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">332</span> (1.30 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m332\u001b[0m (1.30 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.2707 - loss: 1.5045 - val_accuracy: 0.2500 - val_loss: 1.4636\n",
      "Epoch 2/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3221 - loss: 1.3675 - val_accuracy: 0.3500 - val_loss: 1.3581\n",
      "Epoch 3/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3355 - loss: 1.3207 - val_accuracy: 0.4500 - val_loss: 1.2694\n",
      "Epoch 4/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4847 - loss: 1.1923 - val_accuracy: 0.5250 - val_loss: 1.1998\n",
      "Epoch 5/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5978 - loss: 1.1302 - val_accuracy: 0.6500 - val_loss: 1.1339\n",
      "Epoch 6/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6317 - loss: 1.1115 - val_accuracy: 0.7750 - val_loss: 1.0698\n",
      "Epoch 7/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6736 - loss: 1.0342 - val_accuracy: 0.7500 - val_loss: 1.0082\n",
      "Epoch 8/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7505 - loss: 0.9515 - val_accuracy: 0.8500 - val_loss: 0.9452\n",
      "Epoch 9/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8133 - loss: 0.9094 - val_accuracy: 0.9000 - val_loss: 0.8793\n",
      "Epoch 10/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8278 - loss: 0.8859 - val_accuracy: 0.9250 - val_loss: 0.8151\n",
      "Epoch 11/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8844 - loss: 0.7937 - val_accuracy: 0.9250 - val_loss: 0.7549\n",
      "Epoch 12/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9118 - loss: 0.7093 - val_accuracy: 0.9500 - val_loss: 0.7004\n",
      "Epoch 13/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9207 - loss: 0.6884 - val_accuracy: 0.9500 - val_loss: 0.6511\n",
      "Epoch 14/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8836 - loss: 0.6355 - val_accuracy: 0.9500 - val_loss: 0.6060\n",
      "Epoch 15/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8946 - loss: 0.5889 - val_accuracy: 0.9500 - val_loss: 0.5680\n",
      "Epoch 16/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8900 - loss: 0.5503 - val_accuracy: 0.9500 - val_loss: 0.5342\n",
      "Epoch 17/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9235 - loss: 0.4833 - val_accuracy: 0.9500 - val_loss: 0.5039\n",
      "Epoch 18/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9284 - loss: 0.4725 - val_accuracy: 0.9500 - val_loss: 0.4777\n",
      "Epoch 19/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9270 - loss: 0.4483 - val_accuracy: 0.9500 - val_loss: 0.4541\n",
      "Epoch 20/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9204 - loss: 0.3965 - val_accuracy: 0.9500 - val_loss: 0.4344\n",
      "Epoch 21/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9416 - loss: 0.3675 - val_accuracy: 0.9500 - val_loss: 0.4183\n",
      "Epoch 22/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9380 - loss: 0.3780 - val_accuracy: 0.9500 - val_loss: 0.4044\n",
      "Epoch 23/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9307 - loss: 0.3294 - val_accuracy: 0.9500 - val_loss: 0.3911\n",
      "Epoch 24/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9291 - loss: 0.3234 - val_accuracy: 0.9500 - val_loss: 0.3794\n",
      "Epoch 25/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8907 - loss: 0.3776 - val_accuracy: 0.9500 - val_loss: 0.3710\n",
      "Epoch 26/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9309 - loss: 0.2981 - val_accuracy: 0.9500 - val_loss: 0.3623\n",
      "Epoch 27/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9211 - loss: 0.3130 - val_accuracy: 0.9500 - val_loss: 0.3566\n",
      "Epoch 28/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9304 - loss: 0.2911 - val_accuracy: 0.9500 - val_loss: 0.3514\n",
      "Epoch 29/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9357 - loss: 0.2776 - val_accuracy: 0.9500 - val_loss: 0.3463\n",
      "Epoch 30/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9524 - loss: 0.2448 - val_accuracy: 0.9500 - val_loss: 0.3419\n",
      "Epoch 31/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9451 - loss: 0.2251 - val_accuracy: 0.9500 - val_loss: 0.3392\n",
      "Epoch 32/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9101 - loss: 0.2804 - val_accuracy: 0.9500 - val_loss: 0.3383\n",
      "Epoch 33/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9332 - loss: 0.2483 - val_accuracy: 0.9500 - val_loss: 0.3349\n",
      "Epoch 34/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9054 - loss: 0.2164 - val_accuracy: 0.9500 - val_loss: 0.3333\n",
      "Epoch 35/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9480 - loss: 0.2121 - val_accuracy: 0.9500 - val_loss: 0.3319\n",
      "Epoch 36/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9423 - loss: 0.2291 - val_accuracy: 0.9500 - val_loss: 0.3315\n",
      "Epoch 37/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9452 - loss: 0.2166 - val_accuracy: 0.9500 - val_loss: 0.3301\n",
      "Epoch 38/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9367 - loss: 0.2393 - val_accuracy: 0.9500 - val_loss: 0.3310\n",
      "Epoch 39/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9514 - loss: 0.1925 - val_accuracy: 0.9500 - val_loss: 0.3316\n",
      "Epoch 40/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9563 - loss: 0.1685 - val_accuracy: 0.9500 - val_loss: 0.3342\n",
      "Epoch 41/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9687 - loss: 0.1697 - val_accuracy: 0.9500 - val_loss: 0.3346\n",
      "Epoch 42/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9480 - loss: 0.2022 - val_accuracy: 0.9500 - val_loss: 0.3363\n",
      "Epoch 43/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9526 - loss: 0.1919 - val_accuracy: 0.9500 - val_loss: 0.3383\n",
      "Epoch 44/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9549 - loss: 0.1638 - val_accuracy: 0.9500 - val_loss: 0.3410\n",
      "Epoch 45/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9655 - loss: 0.1409 - val_accuracy: 0.9500 - val_loss: 0.3430\n",
      "Epoch 46/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9530 - loss: 0.1644 - val_accuracy: 0.9500 - val_loss: 0.3441\n",
      "Epoch 47/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9641 - loss: 0.1880 - val_accuracy: 0.9500 - val_loss: 0.3477\n",
      "Epoch 48/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9547 - loss: 0.1688 - val_accuracy: 0.9500 - val_loss: 0.3510\n",
      "Epoch 49/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9800 - loss: 0.1377 - val_accuracy: 0.9500 - val_loss: 0.3527\n",
      "Epoch 50/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9671 - loss: 0.1502 - val_accuracy: 0.9500 - val_loss: 0.3563\n",
      "Epoch 51/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9849 - loss: 0.1183 - val_accuracy: 0.9500 - val_loss: 0.3604\n",
      "Epoch 52/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9683 - loss: 0.1373 - val_accuracy: 0.9500 - val_loss: 0.3644\n",
      "Epoch 53/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9468 - loss: 0.1843 - val_accuracy: 0.9500 - val_loss: 0.3673\n",
      "Epoch 54/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9572 - loss: 0.1911 - val_accuracy: 0.9500 - val_loss: 0.3720\n",
      "Epoch 55/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9812 - loss: 0.1221 - val_accuracy: 0.9500 - val_loss: 0.3745\n",
      "Epoch 56/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9598 - loss: 0.1290 - val_accuracy: 0.9500 - val_loss: 0.3815\n",
      "Epoch 57/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9639 - loss: 0.1422 - val_accuracy: 0.9500 - val_loss: 0.3867\n",
      "Epoch 58/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9506 - loss: 0.1812 - val_accuracy: 0.9500 - val_loss: 0.3906\n",
      "Epoch 59/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9615 - loss: 0.1732 - val_accuracy: 0.9500 - val_loss: 0.3963\n",
      "Epoch 60/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9677 - loss: 0.1338 - val_accuracy: 0.9500 - val_loss: 0.3974\n",
      "Epoch 61/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9700 - loss: 0.1224 - val_accuracy: 0.9500 - val_loss: 0.4028\n",
      "Epoch 62/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9568 - loss: 0.1399 - val_accuracy: 0.9500 - val_loss: 0.4086\n",
      "Epoch 63/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9388 - loss: 0.1856 - val_accuracy: 0.9500 - val_loss: 0.4140\n",
      "Epoch 64/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9650 - loss: 0.1178 - val_accuracy: 0.9500 - val_loss: 0.4162\n",
      "Epoch 65/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9684 - loss: 0.1416 - val_accuracy: 0.9500 - val_loss: 0.4203\n",
      "Epoch 66/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9795 - loss: 0.1114 - val_accuracy: 0.9500 - val_loss: 0.4286\n",
      "Epoch 67/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9503 - loss: 0.1879 - val_accuracy: 0.9500 - val_loss: 0.4352\n",
      "Epoch 68/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9789 - loss: 0.1047 - val_accuracy: 0.9500 - val_loss: 0.4378\n",
      "Epoch 69/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9683 - loss: 0.1224 - val_accuracy: 0.9500 - val_loss: 0.4444\n",
      "Epoch 70/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9298 - loss: 0.2108 - val_accuracy: 0.9500 - val_loss: 0.4520\n",
      "Epoch 71/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9716 - loss: 0.0966 - val_accuracy: 0.9500 - val_loss: 0.4550\n",
      "Epoch 72/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9436 - loss: 0.1883 - val_accuracy: 0.9500 - val_loss: 0.4614\n",
      "Epoch 73/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9643 - loss: 0.1205 - val_accuracy: 0.9500 - val_loss: 0.4681\n",
      "Epoch 74/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9450 - loss: 0.1677 - val_accuracy: 0.9500 - val_loss: 0.4730\n",
      "Epoch 75/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9790 - loss: 0.0983 - val_accuracy: 0.9500 - val_loss: 0.4782\n",
      "Epoch 76/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9540 - loss: 0.1387 - val_accuracy: 0.9500 - val_loss: 0.4848\n",
      "Epoch 77/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9638 - loss: 0.1521 - val_accuracy: 0.9500 - val_loss: 0.4892\n",
      "Epoch 78/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9632 - loss: 0.1190 - val_accuracy: 0.9500 - val_loss: 0.4933\n",
      "Epoch 79/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9639 - loss: 0.1222 - val_accuracy: 0.9500 - val_loss: 0.5008\n",
      "Epoch 80/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9438 - loss: 0.1539 - val_accuracy: 0.9500 - val_loss: 0.5062\n",
      "Epoch 81/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9600 - loss: 0.1355 - val_accuracy: 0.9500 - val_loss: 0.5123\n",
      "Epoch 82/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9400 - loss: 0.1474 - val_accuracy: 0.9500 - val_loss: 0.5153\n",
      "Epoch 83/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9737 - loss: 0.0875 - val_accuracy: 0.9500 - val_loss: 0.5210\n",
      "Epoch 84/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9684 - loss: 0.1109 - val_accuracy: 0.9500 - val_loss: 0.5266\n",
      "Epoch 85/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9729 - loss: 0.1026 - val_accuracy: 0.9500 - val_loss: 0.5308\n",
      "Epoch 86/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9705 - loss: 0.1132 - val_accuracy: 0.9500 - val_loss: 0.5360\n",
      "Epoch 87/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9592 - loss: 0.1607 - val_accuracy: 0.9500 - val_loss: 0.5418\n",
      "Epoch 88/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9581 - loss: 0.1389 - val_accuracy: 0.9500 - val_loss: 0.5477\n",
      "Epoch 89/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9540 - loss: 0.1673 - val_accuracy: 0.9500 - val_loss: 0.5516\n",
      "Epoch 90/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9468 - loss: 0.1603 - val_accuracy: 0.9500 - val_loss: 0.5539\n",
      "Epoch 91/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9555 - loss: 0.1332 - val_accuracy: 0.9500 - val_loss: 0.5595\n",
      "Epoch 92/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9714 - loss: 0.1017 - val_accuracy: 0.9500 - val_loss: 0.5652\n",
      "Epoch 93/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9835 - loss: 0.0729 - val_accuracy: 0.9500 - val_loss: 0.5725\n",
      "Epoch 94/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9415 - loss: 0.1571 - val_accuracy: 0.9500 - val_loss: 0.5767\n",
      "Epoch 95/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9512 - loss: 0.1481 - val_accuracy: 0.9500 - val_loss: 0.5824\n",
      "Epoch 96/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9712 - loss: 0.1158 - val_accuracy: 0.9500 - val_loss: 0.5868\n",
      "Epoch 97/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9752 - loss: 0.1003 - val_accuracy: 0.9500 - val_loss: 0.5904\n",
      "Epoch 98/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9590 - loss: 0.1201 - val_accuracy: 0.9500 - val_loss: 0.5944\n",
      "Epoch 99/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9540 - loss: 0.1497 - val_accuracy: 0.9500 - val_loss: 0.6007\n",
      "Epoch 100/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9598 - loss: 0.1244 - val_accuracy: 0.9500 - val_loss: 0.6046\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9458 - loss: 0.6495 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Score: 0.604618489742279\n",
      "Validation Accuracy: 0.949999988079071\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the datasets\n",
    "train_df = pd.read_csv(\"training.csv\")\n",
    "test_df = pd.read_csv(\"testing.csv\")\n",
    "\n",
    "# # Display unique values in each column\n",
    "# print(\"\\nUnique values in each column:\")\n",
    "# for column in train_df.columns:\n",
    "#     print(f\"{column}: {train_df[column].nunique()} unique values\")\n",
    "\n",
    "# Encode the 'class' column\n",
    "label_encoder = LabelEncoder()\n",
    "train_df['class'] = label_encoder.fit_transform(train_df['class'].str.strip())\n",
    "\n",
    "# Separate features and target variable in training data\n",
    "columns_to_drop = ['class', 'pred_minus_obs_H_b1', 'pred_minus_obs_H_b2', 'pred_minus_obs_H_b3',\n",
    "       'pred_minus_obs_H_b4', 'pred_minus_obs_H_b5', 'pred_minus_obs_H_b6',\n",
    "       'pred_minus_obs_H_b7', 'pred_minus_obs_H_b8', 'pred_minus_obs_H_b9',\n",
    "       'pred_minus_obs_S_b1', 'pred_minus_obs_S_b2', 'pred_minus_obs_S_b3',\n",
    "       'pred_minus_obs_S_b4', 'pred_minus_obs_S_b5', 'pred_minus_obs_S_b6',\n",
    "       'pred_minus_obs_S_b7', 'pred_minus_obs_S_b8', 'pred_minus_obs_S_b9']\n",
    "X = train_df.drop(columns=columns_to_drop)\n",
    "y = train_df['class']\n",
    "\n",
    "# One-hot encoding the target variable\n",
    "y = to_categorical(y)\n",
    "\n",
    "# Normalize the feature data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Define model parameters\n",
    "DENSE1_SIZE = 16  # Increased size for more capacity\n",
    "DENSE2_SIZE = 8\n",
    "NUM_OF_EPOCHS = 100  # Increased epochs for better training\n",
    "BATCH_SIZE = 16  # Adjusted batch size\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(X_train.shape[1],)))\n",
    "model.add(tf.keras.layers.Dense(DENSE1_SIZE, activation='relu'))\n",
    "# model.add(tf.keras.layers.Dropout(0.3))  # Added dropout for regularization\n",
    "model.add(tf.keras.layers.Dense(DENSE2_SIZE, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=NUM_OF_EPOCHS, \n",
    "                    verbose=1, validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate the model on validation data\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=1)\n",
    "print(\"Validation Score:\", val_loss)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "\n",
    "# Save the model\n",
    "model.save('ForestTypeMappingModel.h5')\n",
    "\n",
    "# Preprocess the testing data similarly\n",
    "test_df['class'] = label_encoder.transform(test_df['class'].str.strip())\n",
    "X_test = test_df.drop(columns=columns_to_drop)\n",
    "y_test = to_categorical(test_df['class'])\n",
    "\n",
    "# Normalize the test data using the same scaler\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d53a89d0-abaf-4620-ab54-9cbb2fcaf30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8035 - loss: 0.6087 \n",
      "Test Score: 0.5918241739273071\n",
      "Test Accuracy: 0.8215384483337402\n",
      "<generator object representative_dataset at 0x0000017CFBAE7100>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test, verbose=1)\n",
    "print(\"Test Score:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "def representative_dataset():\n",
    "    for _ in range(100):\n",
    "        data = X_test_scaled.astype(np.float32)\n",
    "        yield [data]\n",
    "\n",
    "print(representative_dataset())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "147fe252-97da-4576-9da5-6ebd45eaf6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save('ForestTypeMappingModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "192875dc-2f77-40e2-80cb-dac9a893248a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\vedan\\AppData\\Local\\Temp\\tmpms0amj6n\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\vedan\\AppData\\Local\\Temp\\tmpms0amj6n\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\vedan\\AppData\\Local\\Temp\\tmpms0amj6n'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 9), dtype=tf.float32, name='keras_tensor_123')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1636309726032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1636309727568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1636309727376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1636309728720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1636309728528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1636309728144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedan\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\lite\\python\\convert.py:983: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been converted and saved as 'ForestTypeMappingModel.tflite'.\n"
     ]
    }
   ],
   "source": [
    "# Convert the model to TensorFlow Lite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# Apply optimizations (optional)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Representative dataset for quantization (provide a function for this)\n",
    "def representative_dataset():\n",
    "    for _ in range(100):\n",
    "        yield [X_train.astype(np.float32)]  # Use training data or any relevant subset\n",
    "\n",
    "converter.representative_dataset = representative_dataset\n",
    "\n",
    "# Convert the model\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the converted model\n",
    "with open('ForestTypeMappingModel.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"Model has been converted and saved as 'ForestTypeMappingModel.tflite'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d91d27c1-13b6-413d-a082-a6f49d7919ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input details:\n",
      " [{'name': 'serving_default_keras_tensor_123:0', 'index': 0, 'shape': array([1, 9]), 'shape_signature': array([-1,  9]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "Output details:\n",
      " [{'name': 'StatefulPartitionedCall_1:0', 'index': 14, 'shape': array([1, 4]), 'shape_signature': array([-1,  4]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "# Load the TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=\"ForestTypeMappingModel.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors details.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print('Input details:\\n', input_details)\n",
    "print('Output details:\\n', output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f059aad3-379a-44d1-81ae-4473250a8595",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Input Inference Output:\n",
      "[[0.0625     0.046875   0.87109375 0.015625  ]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "Keras Model Prediction Output for Random Input:\n",
      "[[0.06687031 0.04668427 0.868763   0.01768244]]\n"
     ]
    }
   ],
   "source": [
    "# Test the model on random input data.\n",
    "input_shape = input_details[0]['shape']\n",
    "random_input_data = np.random.random_sample(input_shape).astype(np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], random_input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get the output tensor.\n",
    "random_output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(\"Random Input Inference Output:\")\n",
    "print(random_output_data)\n",
    "\n",
    "# Verify if the same random input data is given to the original model, what is the output\n",
    "keras_output = model.predict(random_input_data)\n",
    "print(\"Keras Model Prediction Output for Random Input:\")\n",
    "print(keras_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "70a10fd3-40cc-4ab5-96d3-a269d159d326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled Input: [[-0.93741743  0.89837465  0.77143262 -0.77259708  2.44858083  2.00219009\n",
      "   0.41152528  2.04444149  2.24164257]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedan\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Suppose scaler is already fitted on the training data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)  # Where X is the feature set from the training data\n",
    "\n",
    "# Sample input\n",
    "input_data = np.array([51 , 57  ,77 ,  90  ,89  ,123 ,  97 , 47,  83]).reshape(1, -1)\n",
    "\n",
    "# Scale the input\n",
    "scaled_input = scaler.transform(input_data)\n",
    "print(\"Scaled Input:\", scaled_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e2cb5400-dac7-434a-94a6-a2c4e236c106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assume we have the label encoder used during training\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.classes_ = np.array(['d','h','o','s'])  # Replace with your actual class names\n",
    "\n",
    "# Load the TFLite model and allocate tensors\n",
    "interpreter = tf.lite.Interpreter(model_path=\"ForestTypeMappingModel.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "80a6577e-f610-4a37-8bd1-995c9b6feaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output Probabilities: [0.9296875  0.00390625 0.0234375  0.04296875]\n",
      "Predicted Forest Class: d\n"
     ]
    }
   ],
   "source": [
    "# Define a sample input (e.g., one row of normalized test data)\n",
    "# Adjust values as needed for meaningful test cases\n",
    "specific_input_data = np.array([[-1.8787969 , -0.28223274, -0.3865936 , -0.7048794, 0.02165439 , 0.03122059,\n",
    "   0.15428138 ,-0.18893459 ,-0.11433257]], dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], specific_input_data)\n",
    "\n",
    "# Run inference\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get the output tensor (predicted probabilities)\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])[0]\n",
    "print(\"Model Output Probabilities:\", output_data)\n",
    "\n",
    "# Get the index of the highest probability, which corresponds to the predicted class\n",
    "predicted_class_index = np.argmax(output_data)\n",
    "\n",
    "# Decode the class index back to the original class label\n",
    "predicted_class_label = label_encoder.inverse_transform([predicted_class_index])[0]\n",
    "print(\"Predicted Forest Class:\", predicted_class_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7a832ff9-cad9-436f-bb41-c6e9eb1e4d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output Probabilities: [0.00390625 0.95703125 0.         0.0390625 ]\n",
      "Predicted Forest Class: h\n"
     ]
    }
   ],
   "source": [
    "# Define a sample input (e.g., one row of normalized test data)\n",
    "# Adjust values as needed for meaningful test cases\n",
    "specific_input_data = np.array([[ 1.72982439, -0.73198794, -0.44449491,  1.25893309 ,-0.54462844 ,-0.23754798\n",
    "  , 0.66876918, -0.18893459,  0.39783594]], dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], specific_input_data)\n",
    "\n",
    "# Run inference\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get the output tensor (predicted probabilities)\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])[0]\n",
    "print(\"Model Output Probabilities:\", output_data)\n",
    "\n",
    "# Get the index of the highest probability, which corresponds to the predicted class\n",
    "predicted_class_index = np.argmax(output_data)\n",
    "\n",
    "# Decode the class index back to the original class label\n",
    "predicted_class_label = label_encoder.inverse_transform([predicted_class_index])[0]\n",
    "print(\"Predicted Forest Class:\", predicted_class_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c004b881-b11d-4d13-87d1-ce4b4fb52b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output Probabilities: [0.        0.0078125 0.        0.9921875]\n",
      "Predicted Forest Class: s\n"
     ]
    }
   ],
   "source": [
    "# Define a sample input (e.g., one row of normalized test data)\n",
    "# Adjust values as needed for meaningful test cases\n",
    "specific_input_data = np.array([[-0.54517599 ,-0.67576854, -0.79190278, -0.56944406, -0.62552599, -0.59590607,\n",
    "  -0.87469423, -0.3006034 , -0.31919997]], dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], specific_input_data)\n",
    "\n",
    "# Run inference\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get the output tensor (predicted probabilities)\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])[0]\n",
    "print(\"Model Output Probabilities:\", output_data)\n",
    "\n",
    "# Get the index of the highest probability, which corresponds to the predicted class\n",
    "predicted_class_index = np.argmax(output_data)\n",
    "\n",
    "# Decode the class index back to the original class label\n",
    "predicted_class_label = label_encoder.inverse_transform([predicted_class_index])[0]\n",
    "print(\"Predicted Forest Class:\", predicted_class_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0349ca77-8712-4c68-a305-f61a31e88ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output Probabilities: [0.00390625 0.         0.99609375 0.        ]\n",
      "Predicted Forest Class: o\n"
     ]
    }
   ],
   "source": [
    "# Define a sample input (e.g., one row of normalized test data)\n",
    "# Adjust values as needed for meaningful test cases\n",
    "specific_input_data = np.array([[-0.93741743 , 0.89837465,  0.77143262, -0.77259708,  2.44858083,  2.00219009\n",
    "   ,0.41152528,  2.04444149 , 2.24164257]], dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], specific_input_data)\n",
    "\n",
    "# Run inference\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get the output tensor (predicted probabilities)\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])[0]\n",
    "print(\"Model Output Probabilities:\", output_data)\n",
    "\n",
    "# Get the index of the highest probability, which corresponds to the predicted class\n",
    "predicted_class_index = np.argmax(output_data)\n",
    "\n",
    "# Decode the class index back to the original class label\n",
    "predicted_class_label = label_encoder.inverse_transform([predicted_class_index])[0]\n",
    "print(\"Predicted Forest Class:\", predicted_class_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d917db96-a60b-4842-a0b6-24cc49912532",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
